---
title: "STATS 506 Problem 3"
author: "Lindsey Lin"
format: pdf
editor: visual
---

#### GitHub Repository Link: <https://github.com/ziyelinlin/STATS-506-Problem-Set-3.git>

```{r package_loading}
library(knitr)
library(haven)
library(tidyverse)
library(broom)
library(pscl)
library(emmeans)
library(DBI)
library(RSQLite)
library(microbenchmark)
```

## Problem 1 NHANES

a\. Download the file AUX_I from [this location](https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Examination&CycleBeginYear=2015), and determine how to **read it into R**. Then download the file DEMO_I from [this location](http://wwwn.cdc.gov/Nchs/Nhanes/Search/DataPage.aspx?Component=Demographics&CycleBeginYear=2015). Note that each page contains a link to a documentation file for that data set. **Merge the two** files to create a single `data.frame`. **Keep only records which matched**. Print out the **dimensions** of the merged `data.frame`.

```{r data_loading}
audiometry <- as.data.frame(read_xpt("AUX_I.xpt"))
demo <- as.data.frame(read_xpt("DEMO_I.xpt"))
merged_df <- merge(audiometry, demo, by = "SEQN")

dim(merged_df)
```

**Answer**:

Merged two files by `SEQN`, the returned data frame has 4582 rows and 119 columns.

b\. We’ll be using the **following variables.** Clean up each - ensure **all missing values are actually `NA`** (rather than `999` or something), and if it’s categorical, convert it to `factor` with informative `levels`.

-   Gender

-   Citizenship status

-   Number of children 5 years or younger in the household

-   Annual household income - There’s also an issue with the ordering of the categories here; take a look, identify the issue, and implement a solution.

```{r variable_selection_rename}
tymp_demo_df <- merged_df %>% 
  select("SEQN", 
         "tymp_right" = "AUXTWIDR",
         "tymp_left" = "AUXTWIDL",
         "gender" = "RIAGENDR",
         "citizenship" = "DMDCITZN",
         "num_children_5_younger" = "DMDHHSZA",
         "annual_income_code" = "INDHHIN2")

head(tymp_demo_df)
```

```{r variables_cleaning_labeling}
tymp_demo <- tymp_demo_df %>% 
  mutate(
    gender = factor(gender, 
                    levels = c(1, 2), 
                    labels = c("Male", "Female")),
    
    citizenship = case_when(citizenship %in% c(7, 9) ~ NA, 
                            TRUE ~ citizenship),
    
    citizenship = factor(citizenship,
                         levels = c(1, 2),
                         labels = c("U.S. citizen", "Not a citizen")),
    
    annual_income_code = case_when(annual_income_code %in% c(12, 13) ~ NA,
                                   annual_income_code %in% c(77, 99) ~ NA,
                                   TRUE ~ annual_income_code),
    
    annual_income_range = factor(annual_income_code, 
                           ordered = TRUE, 
                           levels = c(1:10, 14, 15),
                           labels = c("$0–4,999", 
                                      "$5,000–9,999",
                                      "$10,000–14,999",
                                      "$15,000–19,999", 
                                      "$20,000–24,999", 
                                      "$25,000–34,999",
                                      "$35,000–44,999",
                                      "$45,000–54,999",
                                      "$55,000–64,999",
                                      "$65,000–74,999",
                                      "$75,000–99,999",
                                      "$100,000 and Over"))
         )
```

**Answer:**

I selected and renamed the columns needed in this problem, then cleaned and labeled the variables based on the NHANES documentation.

I converted `gender` to factor with 'Male' and 'Female' labels.

For `citizenship`, codes 7 = 'Refused' and 9 = 'Don’t know' were set to `NA`. Then I converted this variable into a factor with 1 = 'U.S. citizen', 2 = 'Not a citizen'.

The original `annual_income_code` is categorical; however, codes 12 = '\$20,000 and over' and 13 = 'Under \$20,000' overlap the detailed ranges, for which they cannot be placed on the same ordered scale as 1–10, 14, 15. Also, 77 = 'Refused' and 99 = 'Don’t know' are non-responses.

So 12, 13, 77, 99 were all set to `NA` to create a meaningful ordered factor. Finally, the remaining detailed bins are labeled and ordered from lowest to highest (I verified the ordering and counts with a frequency table to confirm the levels and the number of `NA`s introduced.)

```{r check_ordering}
fre_table <- as.data.frame(table(tymp_demo$annual_income_range, 
                                 useNA = "ifany"))

names(fre_table) <- c("Income Range", "Count")
kable(fre_table, caption = "Distribution of annual household income")
```

c\. The Tympanometric width measure is looks approximately like a **Poisson distribution**. Fit four Poisson regression models predicting a respondent’s Tympanometric width **in each ear**. Each model is defined below, for a specific ear and a specific set of covariates.

-   1R - Right ear: gender

-   2R - Right ear: gender, citizenship status (as categorical), number of children (as continuous), annual household income (as continuous)

-   1L - Left ear: gender

-   2L - Left ear: gender, citizenship status (as categorical), number of children (as continuous), annual household income (as continuous)

Produce a table presenting the **estimated incidence risk ratios for the coefficients** in each model, along with the **sample size** for the model, the **pseudo-**$R^2$**,** and **AIC** values. (This can be a single table, or one table for coefficients and a separate table for model statistics).

```{r convert_income_continuous}
tymp_demo <- tymp_demo %>% 
  mutate(income_rank = as.integer(annual_income_range))
```

```{r poisson_regression}
m_1R <- glm(tymp_right ~ gender, data = tymp_demo, family = poisson)

m_2R <- glm(tymp_right ~ gender + citizenship + 
                         num_children_5_younger + income_rank,
            data = tymp_demo, family = poisson)

m_1L <- glm(tymp_left ~ gender, data = tymp_demo, family = poisson)

m_2L <- glm(tymp_left ~ gender + citizenship + 
                        num_children_5_younger + income_rank,
            data = tymp_demo, family = poisson)
```

```{r irr_fucntion}
#' irr: Compute the estimated incidence risk ratios for the coefficients
#' and tags each row with the model name provided.
#'
#' @param fit A fitted model object 
#' @param model_name A character string giving a name or label for the model.
#' @return A data frame with 3 columns: model, term, and IRR

irr <- function(fit, model_name){
  tidy(fit) %>% 
    mutate(model = model_name,
           IRR = exp(estimate)) %>% 
    select(model, term, IRR)
}
```

```{r incidence_risk_ratios}

rbind(irr(m_1R, "Model 1"), 
      irr(m_2R, "Model 2"), 
      irr(m_1L, "Model 3"), 
      irr(m_2L, "Model 4")) %>% 
  
  filter(term != "(Intercept)") %>% 
  
  mutate(term = recode(
    term,
    "genderFemale" = "Gender: Female",
    "citizenshipNot a citizen" = "Citizenship: Not a citizen",
    "num_children_5_younger" = "Num of children 5 years or younger",
    "income_rank" = "Income rank")) %>% 
  
  pivot_wider(names_from = model, values_from = IRR) %>% 
  
  mutate(across(-term, ~ round(.x, 4))) %>% 
  
  kable(caption = "Incidence Risk Ratios by Models", 
        align = c("l","c","c","c","c"))
```

```{r model_stats_function}
#' model_stats: Computes sample size (N), McFadden's pseudo-R², 
#' and AIC for a fitted Poisson regression model.
#' 
#' @param model A fitted model object
#' @return A named numeric vector with 3 elements

model_stats <- function(model) {
  return(c(N = length(model$fitted.values),
    R2 = pR2(model)["McFadden"],
    AIC = AIC(model)))
}
```

```{r statistics_glm}
stats_raw <- cbind(model_stats(m_1R),
                   model_stats(m_2R),
                   model_stats(m_1L),
                   model_stats(m_2L))

stats_table <- rbind(formatC(stats_raw[1, ], format = "d"),              
                     formatC(stats_raw[2, ], format = "f", digits = 4),  
                     formatC(stats_raw[3, ], format = "f", digits = 2))

rownames(stats_table) <- c("Sample Size", "Pseudo R²", "AIC")
colnames(stats_table) <- c("Model 1", "Model 2", "Model 3", "Model 4")

kable(stats_table, caption = "Model Statistics")
```

Note:

To treat annual household income as a continuous predictor, I treated the numeric labels of the groups as continuous, for which I converted the ordered income categories to numeric ranks from 1 (lowest) to 12 (highest), using `income_rank = as.integer(annual_income_range)`.

d\. From model 2L, provide evidence whether there is a **difference between males and females** in terms of their incidence risk ratio. **Test whether the predicted value** of Tympanometric width measure of the left ear **differs between men and women**. Include the results of the **each test** and their **interpretation**.

```{r}
summary(m_2L)
```

```{r}
emmeans(m_2L, ~ gender, type = "response")
```

```{r}
pairs(emmeans(m_2L, ~ gender, type = "response"))
```

Answer:

From the summary output of model 2L and Table 2, we can see that the p-value for the gender coefficient is very small, and the IRR is slightly above 1. This provides strong evidence that females differ from males in their expected tympanometric width, after adjusting for other variables. On average, females have about 1.9% higher expected width than males.

To test whether the predicted tympanometric width of the left ear differs between men and women, I used the `emmeans()` function with model 2L. The estimated ratio (male vs. female) of predicted means was 0.982 with a p-value \< 0.0001, indicating that this difference is statistically significant. Therefore, we can conclude that males have significantly lower predicted tympanometric width than females, after adjusting for other variables.

## Problem 2 **Sakila**

For these problems, **do not** use any of the tables whose names end in `_list`.

For each of the following questions, solve them in two ways:

-   First, use SQL query or queries to extract the appropriate table(s), then use regular R operations on those `data.frame`s to answer the question.

-   Second, use a single SQL query to answer the question.

Compare each approach using microbenchmark.

```{r SQL_connection}
sakila <- dbConnect(RSQLite::SQLite(), "sakila_master.db")
```

```{r get_query_function}
#' get_query: Run a SQL query on the sakila database.
#' 
#' @param query A character string containing a valid SQL query.
#' @return A data frame with the result of the SQL query.
get_query <- function(query) dbGetQuery(sakila, query)
```

a\. For each store, how many customers does that store have, and what percentage of customers of that store are active in the system?

```{r r_version_2a}
customer <- dbReadTable(sakila, "customer")
customer_summary_r_2a <- customer %>% 
  group_by(store_id) %>% 
  summarise(customer_count = n(),
            percent_active = round(mean(active == 1) * 100,2))

kable(customer_summary_r_2a, 
      caption = "Customer counts and percent active by store (R version)")
```

```{r sql_version_2a}
customer_summary_sql_2a <- get_query("
SELECT store_id,
       COUNT(*) AS customer_count,
       ROUND(AVG(active = 1)* 100, 2) AS percent_active
  FROM customer
 GROUP BY store_id
                                     ")

kable(customer_summary_sql_2a, 
      caption = "Customer counts and percent active by store (SQL version)")
```

```{r time_comparison_2a}
microbenchmark(
  R = {
    dbReadTable(sakila, "customer") %>% 
      group_by(store_id) %>% 
      summarise(customer_count = n(), 
                percent_active = round(mean(active == 1) * 100,2))
  },
  
  SQL = {
    get_query("
      SELECT store_id,
             COUNT(*) AS customer_count,
             ROUND(AVG(active = 1)* 100, 2) AS percent_active
        FROM customer
       GROUP BY store_id
    ")
  },
  times = 20,
  unit = "ms"
)
```

Answer:

Store 1 has 326 customers and 97.55% of customers are active in the system. Store 2 has 273 customers and 97.44% of customers are active in the system. Based on the microbenchmark results, the SQL approach was much faster than the R approach.

b\. Generate a table identifying the names and country of **each staff member**.

```{r r_version_2b}
staff <- dbReadTable(sakila, "staff")
address <- dbReadTable(sakila, "address")
city <- dbReadTable(sakila, "city")
country <- dbReadTable(sakila, "country")

staff_country_r <- staff %>% 
  left_join(address, by = "address_id") %>% 
  left_join(city, by = "city_id") %>% 
  left_join(country, by = "country_id") %>% 
  select(first_name, last_name, country)

kable(staff_country_r, caption = "Staff Information (R version)")
```

```{r sql_version_2b}
staff_country_sql <- get_query("
SELECT first_name,
       last_name,
       country
  FROM staff AS s
       LEFT JOIN address AS a ON s.address_id = a.address_id
       LEFT JOIN city AS c ON a.city_id = c.city_id
       LEFT JOIN country AS co ON co.country_id = c.country_id
                               ")

kable(staff_country_sql, caption = "Staff Information (SQL version)")
```

```{r time_comparison_2b}
microbenchmark(
  R = {
    staff <- dbReadTable(sakila, "staff")
    address <- dbReadTable(sakila, "address")
    city <- dbReadTable(sakila, "city")
    country <- dbReadTable(sakila, "country")
    
    staff_country_r <- staff %>% 
      left_join(address, by = "address_id") %>% 
      left_join(city, by = "city_id") %>% 
      left_join(country, by = "country_id") %>% 
      select(first_name, last_name, country)
  },
  SQL = {
    staff_country_sql <- get_query("
      SELECT first_name,
             last_name,
             country
        FROM staff AS s
             LEFT JOIN address AS a ON s.address_id = a.address_id
             LEFT JOIN city AS c ON a.city_id = c.city_id
             LEFT JOIN country ON country.country_id = c.country_id
                               ")
  },
  times = 20,
  unit = "ms"
)
```

Answer:

Mike Hillyer is from Canada and Jon Stephens is from Australia. Again, SQL approach was much faster.

c\. Identify the **name(s)** of the film(s) which was/were rented for the **highest dollar value**. (Assume all costs are in USD regardless of country.) (Hint: You can merge a table more than once.)

```{r r_version_2c}
payment <- dbReadTable(sakila, "payment")
rental <- dbReadTable(sakila, "rental")
inventory <- dbReadTable(sakila, "inventory")
film <- dbReadTable(sakila, "film")

highest_rentals_r <- payment %>% 
  filter(amount == max(amount, na.rm = TRUE)) %>% 
  left_join(rental, by = "rental_id") %>% 
  left_join(inventory, by = "inventory_id") %>% 
  left_join(film, by = "film_id") %>% 
  select(title, amount)

kable(highest_rentals_r, 
      caption = "Films rented for the highest dollar value (R version)")
```

```{r sql_version_2c}
highest_rentals_sql <- get_query("
SELECT f.title, 
       p.amount
  FROM payment AS p
       LEFT JOIN rental AS r ON p.rental_id = r.rental_id
       LEFT JOIN inventory AS i ON r.inventory_id = i.inventory_id
       LEFT JOIN film AS f ON i.film_id = f.film_id
WHERE p.amount = (SELECT MAX(amount) FROM payment)")

kable(highest_rentals_sql, 
      caption = "Films rented for the highest dollar value (SQL version)")
```

```{r time_comparison_2c}
microbenchmark(
  R = {
    payment <- dbReadTable(sakila, "payment")
    rental <- dbReadTable(sakila, "rental")
    inventory <- dbReadTable(sakila, "inventory")
    film <- dbReadTable(sakila, "film")
    
    highest_rentals_r <- payment %>% 
      filter(amount == max(amount, na.rm = TRUE)) %>% 
      left_join(rental, by = "rental_id") %>% 
      left_join(inventory, by = "inventory_id") %>% 
      left_join(film, by = "film_id") %>% 
      select(title, amount)
  },
  SQL = {
    highest_rentals_sql <- get_query("
      SELECT f.title, 
             p.amount
        FROM payment AS p
             LEFT JOIN rental AS r ON p.rental_id = r.rental_id
             LEFT JOIN inventory AS i ON r.inventory_id = i.inventory_id
             LEFT JOIN film AS f ON i.film_id = f.film_id
      WHERE p.amount = (SELECT MAX(amount) FROM payment)")
  },
  times = 20,
  unit = "ms"
)
```

Answer:

10 films were rented for the highest dollar value of \$11.99. SQL approach was substantially faster.

## Problem 3 **Australian Records**

Download the “Australia - 500 Records” data from <https://www.briandunning.com/sample-data/> and import it into R. This is entirely fake data; you can read the website for details. Use it to answer the following questions.

```{r}
dat <- read.csv("au-500.csv")
```

a\. What **percentage** of the websites are **.com**’s (as opposed to .net, .com.au, etc)?

```{r}
length(dat$web[grepl("\\.com$", dat$web)]) / nrow(dat)
```

Answer:

The result is 0, none of the website URLs end with ".com".

b\. What is the **most common domain name** amongst the email addresses? (“umich.edu” is the domain name in the email “statistics\@umich.edu”.)

```{r}
email_domains <- sub(".*@", "", dat$email)
most_common <- sort(table(email_domains), decreasing = TRUE)
head(most_common, 1)
```

Answer:

The most common domain name is "hotmail.com".

c\. What **proportion of company names** contain a **non-alphabetic character**, excluding **commas and white spaces**. (E.g. “Jane Doe, LLC” would *not* contain an eligible non-alphabetic character; “Plumber 247” would.) What about if you **also exclude ampersands** (“&”)?

```{r}
mean(grepl("[^A-Za-z ,]", dat$company_name)) *100
```

```{r}
head(dat$company_name[grepl("[^A-Za-z ,]", dat$company_name)])
```

```{r}
mean(grepl("[^A-Za-z ,&]", dat$company_name)) *100
```

```{r}
dat$company_name[grepl("[^A-Za-z ,&]", dat$company_name)]
```

Answer:

If only consider non-alphabetic character with the exclusion of commas and white spaces, 45 company names contain a non-alphabetic character, which is 9%.

If we decide to also exclude &, then only 4 company names contain a non-alphabetic character, which is only 0.8%.

d\. In Australia, phone have 10 digits - but unlike in the US where we write all numbers as “123-456-7890”, they write land lines and cell phones differently:

-   Landlines: 12-3456-7890

-   Cell phones: 1234-567-890

There are two different phones listed for each record. Make **all** phone numbers written like **cell phones**. Show it works by printing the first 10 phone numbers of each column.

```{r cell_format_function}
#' cell_format: Format phone numbers as Australian cell style. 
#' 
#' @param phone Character vector of phone numbers in arbitrary formats
#' (may include spaces, dashes, parentheses, etc.)
#' @return A character vector the same length as `phone`, where each 
#' element is either a formatted string `"dddd-ddd-ddd"` or `NA` if not 
#' 10 digits.

cell_format <- function(phone){
  parts_list <- gsub("[^0-9]", "", phone)
  ifelse(nchar(parts_list) == 10,
         paste(substring(parts_list, 1, 4),
               substring(parts_list, 5, 7),
               substring(parts_list, 8,10),
               sep = "-"),
         NA)
}
```

```{r}
dat %>% 
  mutate(cell_phone1 = cell_format(phone1),
         cell_phone2 = cell_format(phone2)) %>% 
  select(cell_phone1, cell_phone2) %>% 
  head(10)
```

Answer:

I used `gsub()` instead of `strsplit()` so that it can handle any formatting of the phone number.

e\. Produce a histogram of the **log of the apartment numbers** for all addresses. (You may assume **any number** **at the end** of the an address is an **apartment number.**)

```{r}
has_apt_num <- dat$address[grepl("[0-9]+$", dat$address)]
apt_num <- sapply(strsplit(has_apt_num, " "), function(add) add[length(add)])
apt_num <- as.numeric(sub("#", "", apt_num))
hist(log(apt_num),
     main = "Hostogram of apartment number on log scale")
```

f\. [Benford’s law](https://en.wikipedia.org/wiki/Benford's_law) is an observation about the distribution of the **leading digit** of real numerical data. Examine whether the apartment numbers appear to follow Benford’s law. Do you think the apartment numbers would pass as real data?

```{r benford_law}
tab <- table(substr(apt_num, 1, 1))
digits <- as.integer(names(tab))
count <- as.integer(tab)
prop <- count / sum(count)

benford <- log10(1 + 1/(1:9))

data.frame(
  digit = digits,
  count = count,
  prop  = round(prop, 4),
  benford_prop = round(benford, 4)
) %>% 
  kable(caption = "Distribution of leading digit of apartment numbers")
```

Answer:

Comparing the actual proportions and the Benford’s expected proportions, we can see that apartment numbers do not follow Benford’s law.
